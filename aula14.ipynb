{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_feather('./base/gs.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_learning_dnn(df_dl, dep_var, classes):\n",
    "    # Separa a variável dependente das demais\n",
    "    deep_feat = df_dl.drop(columns=[dep_var], axis=1)\n",
    "    deep_label = df_dl[dep_var]\n",
    "    # Verifica os tipos das variáveis\n",
    "    categorical_columns = [col for col in deep_feat.columns if len(deep_feat[col].unique()) == 2 or deep_feat[col].dtype == 'O']\n",
    "    continuous_columns = [col for col in deep_feat.columns if len(deep_feat[col].unique()) > 2 and (deep_feat[col].dtype == 'int64' or deep_feat[col].dtype == 'float64')]\n",
    "    # Verifica as colunas para normalização - as demais serão discretizadas - Função Bucketize do Tensor Flow\n",
    "    cols_to_scale = continuous_columns[:]\n",
    "    #cols_to_scale.remove('meses')\n",
    "    # Ajusta as bases de treino e de teste\n",
    "    XX_T = df_dl.drop(columns=[dep_var], axis=1)\n",
    "    XX_t = df_dl.drop(columns=[dep_var], axis=1)\n",
    "    yy_T = df_dl[dep_var]\n",
    "    yy_t = df_dl[dep_var]\n",
    "    # Normaliza as variáveis nas bases de treino e teste\n",
    "    scaler = StandardScaler()\n",
    "    XX_T.loc[:, cols_to_scale] = scaler.fit_transform(XX_T.loc[:, cols_to_scale]) ## Treinamento\n",
    "    XX_t.loc[:, cols_to_scale] = scaler.fit_transform(XX_t.loc[:, cols_to_scale]) ## Teste\n",
    "    # Ajustes das Variáveis Categórica - Não presentes neste modelo\n",
    "    categorical_object_feat_cols = [tf.feature_column.embedding_column(\n",
    "    tf.feature_column.categorical_column_with_hash_bucket(key=col, hash_bucket_size=1000), dimension=len(df_dl[col].unique()))\n",
    "    for col in categorical_columns if df_dl[col].dtype == 'O']\n",
    "    # Ajustes das Variáveis Categórica - Não presentes neste modelo\n",
    "    categorical_integer_feat_cols = [tf.feature_column.embedding_column(\n",
    "    tf.feature_column.categorical_column_with_identity(key=col, num_buckets=2), dimension=len(df_dl[col].unique()))\n",
    "    for col in categorical_columns if df[col].dtype=='int64']\n",
    "    continuous_feat_cols = [tf.feature_column.numeric_column(key=col) for col in continuous_columns] \n",
    "    feat_cols = categorical_object_feat_cols + \\\n",
    "                categorical_integer_feat_cols + \\\n",
    "                continuous_feat_cols\n",
    "    # Rotina de DNN (Deep Neural Network)\n",
    "    input_fun = tf.compat.v1.estimator.inputs.pandas_input_fn(XX_T, yy_T, batch_size=50, num_epochs=1000, shuffle=True)\n",
    "    pred_input_fun = tf.compat.v1.estimator.inputs.pandas_input_fn(XX_t, batch_size=50, shuffle=False)\n",
    "    DNN_model = tf.estimator.DNNClassifier(hidden_units=[10, 10, 10], feature_columns=feat_cols, n_classes=classes)\n",
    "    DNN_model.train(input_fn=input_fun, steps=5000)\n",
    "    # Resgata os resultados da DNN\n",
    "    predictions = DNN_model.predict(pred_input_fun)\n",
    "    pred = list(predictions)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aula 14 - Probabilidade\n",
    "dimensao = 'Country'\n",
    "medidas = ['Sales', 'Quantity', 'Profit']\n",
    "grupo = data.groupby(dimensao)[medidas].mean().reset_index()\n",
    "grupo['Benefit'] = grupo['Profit'].apply(lambda x : 0 if x < 0 else 1)\n",
    "grupo = grupo.set_index(dimensao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Benefit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>394.060364</td>\n",
       "      <td>4.145455</td>\n",
       "      <td>99.278182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>243.007500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>44.332500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>184.140765</td>\n",
       "      <td>2.316327</td>\n",
       "      <td>46.461735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>209.459016</td>\n",
       "      <td>2.598361</td>\n",
       "      <td>53.237459</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>147.466111</td>\n",
       "      <td>3.856410</td>\n",
       "      <td>-47.932812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venezuela</th>\n",
       "      <td>137.050668</td>\n",
       "      <td>3.989691</td>\n",
       "      <td>-57.849023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vietnam</th>\n",
       "      <td>248.302639</td>\n",
       "      <td>3.758491</td>\n",
       "      <td>-7.057474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yemen</th>\n",
       "      <td>82.190400</td>\n",
       "      <td>2.366667</td>\n",
       "      <td>-123.548600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zambia</th>\n",
       "      <td>255.250000</td>\n",
       "      <td>2.460784</td>\n",
       "      <td>68.644412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <td>47.063812</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>-67.859812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sales  Quantity      Profit  Benefit\n",
       "Country                                               \n",
       "Afghanistan  394.060364  4.145455   99.278182        1\n",
       "Albania      243.007500  2.500000   44.332500        1\n",
       "Algeria      184.140765  2.316327   46.461735        1\n",
       "Angola       209.459016  2.598361   53.237459        1\n",
       "Argentina    147.466111  3.856410  -47.932812        0\n",
       "...                 ...       ...         ...      ...\n",
       "Venezuela    137.050668  3.989691  -57.849023        0\n",
       "Vietnam      248.302639  3.758491   -7.057474        0\n",
       "Yemen         82.190400  2.366667 -123.548600        0\n",
       "Zambia       255.250000  2.460784   68.644412        1\n",
       "Zimbabwe      47.063812  2.375000  -67.859812        0\n",
       "\n",
       "[147 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grupo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py:59: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_2301/3411649198.py:33: The name tf.estimator.inputs.pandas_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.pandas_input_fn instead.\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmphcfsxqc_\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmphcfsxqc_', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:60: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 22:39:50.192302: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-24 22:39:50.192335: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-24 22:39:50.192357: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (oanthony86-topicosavanc-s6h15fkx4lj): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adagrad.py:90: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow/python/training/monitored_session.py:914: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 22:39:50.806610: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-24 22:39:50.814894: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-10-24 22:39:50.823578: W tensorflow/core/common_runtime/forward_type_inference.cc:332] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'dnn/zero_fraction/cond/output/_18'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmphcfsxqc_/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.70919955, step = 0\n",
      "INFO:tensorflow:global_step/sec: 525.862\n",
      "INFO:tensorflow:loss = 0.6801567, step = 100 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.283\n",
      "INFO:tensorflow:loss = 0.66529757, step = 200 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.857\n",
      "INFO:tensorflow:loss = 0.6606837, step = 300 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.575\n",
      "INFO:tensorflow:loss = 0.62819993, step = 400 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.719\n",
      "INFO:tensorflow:loss = 0.6248875, step = 500 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.465\n",
      "INFO:tensorflow:loss = 0.61928254, step = 600 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.659\n",
      "INFO:tensorflow:loss = 0.595087, step = 700 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 698.57\n",
      "INFO:tensorflow:loss = 0.6075255, step = 800 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.001\n",
      "INFO:tensorflow:loss = 0.5821042, step = 900 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 725.403\n",
      "INFO:tensorflow:loss = 0.59197164, step = 1000 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.049\n",
      "INFO:tensorflow:loss = 0.5651049, step = 1100 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.192\n",
      "INFO:tensorflow:loss = 0.55702126, step = 1200 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.476\n",
      "INFO:tensorflow:loss = 0.5692589, step = 1300 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.062\n",
      "INFO:tensorflow:loss = 0.5631443, step = 1400 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.682\n",
      "INFO:tensorflow:loss = 0.5567894, step = 1500 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.997\n",
      "INFO:tensorflow:loss = 0.54215485, step = 1600 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 622.955\n",
      "INFO:tensorflow:loss = 0.6007436, step = 1700 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.347\n",
      "INFO:tensorflow:loss = 0.5397419, step = 1800 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.476\n",
      "INFO:tensorflow:loss = 0.5477608, step = 1900 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.339\n",
      "INFO:tensorflow:loss = 0.5318458, step = 2000 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 554.654\n",
      "INFO:tensorflow:loss = 0.5307995, step = 2100 (0.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.044\n",
      "INFO:tensorflow:loss = 0.5150572, step = 2200 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 739.869\n",
      "INFO:tensorflow:loss = 0.52207464, step = 2300 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.032\n",
      "INFO:tensorflow:loss = 0.47094047, step = 2400 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.899\n",
      "INFO:tensorflow:loss = 0.49618408, step = 2500 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.903\n",
      "INFO:tensorflow:loss = 0.45042038, step = 2600 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.43\n",
      "INFO:tensorflow:loss = 0.43603826, step = 2700 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.722\n",
      "INFO:tensorflow:loss = 0.46477342, step = 2800 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.184\n",
      "INFO:tensorflow:loss = 0.46953592, step = 2900 (0.147 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2940...\n",
      "INFO:tensorflow:Saving checkpoints for 2940 into /tmp/tmphcfsxqc_/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2940...\n",
      "INFO:tensorflow:Loss for final step: 0.43775177.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmphcfsxqc_/model.ckpt-2940\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Benefit</th>\n",
       "      <th>dl_classe</th>\n",
       "      <th>lucro_0</th>\n",
       "      <th>lucro_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>394.060364</td>\n",
       "      <td>4.145455</td>\n",
       "      <td>99.278182</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324976</td>\n",
       "      <td>0.675024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>243.007500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>44.332500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326585</td>\n",
       "      <td>0.673415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>184.140765</td>\n",
       "      <td>2.316327</td>\n",
       "      <td>46.461735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.293692</td>\n",
       "      <td>0.706308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>209.459016</td>\n",
       "      <td>2.598361</td>\n",
       "      <td>53.237459</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.315542</td>\n",
       "      <td>0.684458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>147.466111</td>\n",
       "      <td>3.856410</td>\n",
       "      <td>-47.932812</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468966</td>\n",
       "      <td>0.531034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>137.050668</td>\n",
       "      <td>3.989691</td>\n",
       "      <td>-57.849023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.470940</td>\n",
       "      <td>0.529060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>248.302639</td>\n",
       "      <td>3.758491</td>\n",
       "      <td>-7.057474</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441238</td>\n",
       "      <td>0.558762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>82.190400</td>\n",
       "      <td>2.366667</td>\n",
       "      <td>-123.548600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484203</td>\n",
       "      <td>0.515797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>255.250000</td>\n",
       "      <td>2.460784</td>\n",
       "      <td>68.644412</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.296541</td>\n",
       "      <td>0.703459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>47.063812</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>-67.859812</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435286</td>\n",
       "      <td>0.564714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country       Sales  Quantity      Profit  Benefit  dl_classe  \\\n",
       "0    Afghanistan  394.060364  4.145455   99.278182        1          1   \n",
       "1        Albania  243.007500  2.500000   44.332500        1          1   \n",
       "2        Algeria  184.140765  2.316327   46.461735        1          1   \n",
       "3         Angola  209.459016  2.598361   53.237459        1          1   \n",
       "4      Argentina  147.466111  3.856410  -47.932812        0          1   \n",
       "..           ...         ...       ...         ...      ...        ...   \n",
       "142    Venezuela  137.050668  3.989691  -57.849023        0          1   \n",
       "143      Vietnam  248.302639  3.758491   -7.057474        0          1   \n",
       "144        Yemen   82.190400  2.366667 -123.548600        0          1   \n",
       "145       Zambia  255.250000  2.460784   68.644412        1          1   \n",
       "146     Zimbabwe   47.063812  2.375000  -67.859812        0          1   \n",
       "\n",
       "      lucro_0   lucro_1  \n",
       "0    0.324976  0.675024  \n",
       "1    0.326585  0.673415  \n",
       "2    0.293692  0.706308  \n",
       "3    0.315542  0.684458  \n",
       "4    0.468966  0.531034  \n",
       "..        ...       ...  \n",
       "142  0.470940  0.529060  \n",
       "143  0.441238  0.558762  \n",
       "144  0.484203  0.515797  \n",
       "145  0.296541  0.703459  \n",
       "146  0.435286  0.564714  \n",
       "\n",
       "[147 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilidade = deep_learning_dnn(grupo, 'Benefit', 2)\n",
    "probabilidade_classe = []\n",
    "for i in range(len(probabilidade)):\n",
    "    probabilidade_classe.append(probabilidade[i][\"class_ids\"][0])\n",
    "probabilidade_prob0 = []\n",
    "for i in range(len(probabilidade)):\n",
    "    probabilidade_prob0.append(probabilidade[i][\"probabilities\"][0])\n",
    "probabilidade_prob1 = []\n",
    "for i in range(len(probabilidade)):\n",
    "    probabilidade_prob1.append(probabilidade[i][\"probabilities\"][1]) \n",
    "grupo['dl_classe'] = probabilidade_classe\n",
    "grupo['lucro_0'] = probabilidade_prob0\n",
    "grupo['lucro_1'] = probabilidade_prob1\n",
    "grupo = grupo.reset_index()\n",
    "grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo.to_feather('base/probabilidade_pais.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
